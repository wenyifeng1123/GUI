# -*- coding: utf-8 -*-
"""
Visualize CNNs

@author: Thomas Kuestner
"""
import theano
import theano.tensor as T
import keras
import os
from keras.models import model_from_json
import numpy as np
import scipy.io as sio
import matplotlib.pyplot as plt
import network_visualization
import argparse


import glob
import yaml
import h5py
from DatabaseInfo import DatabaseInfo
import utils.DataPreprocessing as datapre
import utils.Training_Test_Split as ttsplit
import cnn_main

import keras.optimizers
from keras.models import Sequential, Model
from keras.layers import Input
from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda, Reshape
from keras.activations import relu, elu, softmax
from keras.layers.advanced_activations import LeakyReLU, PReLU
from keras.initializers import Constant
from keras.layers import concatenate, add
from keras.layers.convolutional import Conv3D,Conv2D, MaxPooling3D, MaxPooling2D, ZeroPadding3D
from keras.regularizers import l1_l2,l2
from keras.models import model_from_json
from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau


from networks.motion.CNN2D import *
import utils.DataPreprocessing as datapre
from config import *



# initalize stuff
sTypeVis = 'weights' # deep: lukas implementation, else: weights of first layer
lShow = False



with open('config' + os.sep + 'param.yml', 'r') as ymlfile:
    cfg = yaml.safe_load(ymlfile)

lTrain = cfg['lTrain'] # training or prediction
lSave = cfg['lSave'] # save intermediate test, training sets
dbinfo = DatabaseInfo(cfg['MRdatabase'],cfg['subdirs'])
batchSize = cfg['batchSize']

# load/create input data
patchSize = cfg['patchSize']
if cfg['sSplitting'] == 'normal':
    sFSname = 'normal'
elif cfg['sSplitting'] == 'crossvalidation_data':
    sFSname = 'crossVal_data'
elif cfg['sSplitting'] == 'crossvalidation_patient':
    sFSname = 'crossVal'

sOutsubdir = cfg['subdirs'][2]
sOutPath = cfg['selectedDatabase']['pathout'] + os.sep + ''.join(map(str,patchSize)).replace(" ", "") + os.sep + sOutsubdir # + str(ind_split) + '_' + str(patchSize[0]) + str(patchSize[1]) + '.h5'
sDatafile = sOutPath + os.sep + sFSname + ''.join(map(str,patchSize)).replace(" ", "") + '.h5'


parser = argparse.ArgumentParser(description='''CNN feature visualization''', epilog='''(c) Thomas Kuestner, thomas.kuestner@iss.uni-stuttgart.de''')
parser.add_argument('-i','--inPath', nargs = 1, type = str, help='input path to *.mat', default= '/scratch/med_data/ImageSimilarity/Databases/MRPhysics/CNN/Headcross')
args = parser.parse_args()





if lTrain:
    pass
else:
    ################
    ## prediction ##
    ################
    X_test = np.zeros((0, patchSize[0], patchSize[1]))
    y_test = np.zeros(0)
    for iImg in range(0, len(cfg['lPredictImg'])):
        # patches and labels of reference/artifact
        tmpPatches, tmpLabels = datapre.fPreprocessData(cfg['lPredictImg'][iImg], cfg['patchSize'], cfg['patchOverlap'],
                                                        1, cfg['sLabeling'])
        X_test = np.concatenate((X_test, tmpPatches), axis=0)
        y_test = np.concatenate((y_test, cfg['lLabelPredictImg'][iImg] * tmpLabels), axis=0)

    sNetworktype = cfg['network'].split("_")


    #######################
    ###Predict the model###
    #######################

    #weight_name = sOutPath + model_name + '_weights.h5'

    weight_name = '/no_backup/d1240/CNNArt/results/4040/testout4040_lr_0.001_bs_128_weights.h5'
    # model_all = sOutPath + model_name + '_model.h5'
    model = createModel(patchSize,architecture='new')
    opti = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
    callbacks = [EarlyStopping(monitor='val_loss', patience=10, verbose=1)]

    model.compile(loss='categorical_crossentropy', optimizer=opti, metrics=['accuracy'])

    model.load_weights(weight_name)

    X_test = np.expand_dims(X_test, axis=1)
    y_test = np.asarray([y_test[:], np.abs(np.asarray(y_test[:], dtype=np.float32) - 1)]).T

    score_test, acc_test = model.evaluate(X_test, y_test, batch_size=batchSize)
    prob_pre = model.predict(X_test, batchSize, 1)

    # modelSave = model_name[:-5] + '_pred.mat'
    #modelSave = sOutPath + model_name + '_pred.mat'
    modelSave = '/no_backup/d1240/CNNArt/results/4040/testout4040_lr_0.001_bs_128_pred.mat'
    sio.savemat(modelSave, {'prob_pre': prob_pre, 'score_test': score_test, 'acc_test': acc_test})




if sTypeVis == 'deep':

    #Perform the visualization:
    class_idx = 0
    reg_param = 1/(2e-4)
    output    = model.get_output()
    input     = model.input

    cost 	   = -T.sum(T.log(output[:,class_idx]+1e-8))
    gradient = theano.tensor.grad(cost, input)
    calcGrad = theano.function([input], gradient)
    calcCost = theano.function([input], cost)


    #1. Use Deep Visualization
    #define the cost function (negative log-likelihood for class with class_idx:
    dv     = network_visualization.DeepVisualizer(calcGrad, calcCost, np.random.uniform(0,1.0, size=(1,1,patchSize[0,0],patchSize[0,1])), alpha = reg_param)
    resultDV = dv.optimize(np.random.uniform(0,1.0, size=(1,1,patchSize[0,0],patchSize[0,1])))

    if lShow:
        plt.figure(1)
        plt.title('deep visualizer')
        plt.imshow(resultDV.reshape(patchSize[0],patchSize[1]))
        plt.show()

    print('Saving deep visualization')
    sio.savemat(sSaveName[0] + '_DV.mat', {'resultDV': resultDV})

    #2. Use subset selection:
    step_size = 0.019
    reg_param = 1/(2e-4)

    #data_c = test[100:110] # extract images from the examples as initial point
    resultAll = []
    for i in range(0,len(test),10):
        print('### Patch %d/%d ###' % (i, len(test)))
        data_c = test[i:i+10]
        oss_v  = network_visualization.SubsetSelection(calcGrad, calcCost, data_c, alpha = reg_param, gamma = step_size)
        result = oss_v.optimize(np.random.uniform(0,1.0, size=data_c.shape))
        resultAll.append(result)
        #resultAll = np.concatenate((resultAll,result), axis=0)
        if lShow:
            plt.figure(2)
            plt.title('subset selection')
            plt.imshow(result[0].reshape(40,40))
            plt.show()

    print('Saving subset selection')
    sio.savemat(sSaveName[0] + '_SS.mat', {'resultSS': resultAll})
    #sio.savemat(sDataTest + os.sep + 'visualize_out.mat', {'result': resultAll})

elif sTypeVis == 'keras_weight':
    dataTrain = sio.loadmat(sDataTrain)
    X_train = dataTrain['X_train']
    y_train = dataTrain['y_train']
    ##########
    ##  not working
    ###########
    #convout1 = model.layers[1].output
    from random import randint

    img_to_visualize = randint(0, len(y_train) - 1)

    # Generate function to visualize first layer
    convout1_f = theano.function([model.get_input(train=False)], model.layers[1].get_output(train=False))
    convolutions = convout1_f(X_train[img_to_visualize: img_to_visualize + 1,:,:,:])

   #matplotlib inline
    # The non-magical version of the previous line is this:
    # get_ipython().magic(u'matplotlib inline')
    imshow = plt.imshow  # alias
    #plt.title("Image used: #%d (digit=%d)" % (img_to_visualize, y_train[img_to_visualize]))
    #imshow(X_train[img_to_visualize])

    plt.title("First convolution:")
    imshow(convolutions[0][0])

elif sTypeVis == 'weights':
    #visualize weight vectors
    w = model.layers[0].W.get_value()
    filters = [w[0,:,:] for w in w]
    plt.figure(3)
    plt.title('Weights layer 1')
    for i in range(len(filters)):
        plt.subplot(8,4,i+1)
        plt.imshow(filters[i])
